<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#2D2D2D" />
  
  <title>SpaLoR :: spalor.algorithms.mc_algorithms</title>
  

  <link rel="icon" type="image/png" sizes="32x32" href="../../../_static/img/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../../../_static/img/favicon-16x16.png">
  <link rel="index" title="Index" href="../../../genindex.html"/>

  <link rel="stylesheet" href="../../../_static/css/insegel.css"/>
  <link rel="stylesheet" href="../../../_static/css/custom.css"/>

  <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
  

  <script src="https://email.tl.fortawesome.com/c/eJxNjUEOgyAQAF8jR7Kw6wIHDh7sP1Cw2mgxgmn6-3JsMqc5zEQfE8dkxOY1KKMUOI3ACFKRJpSW2AAp7ontYIaxI6i7XPJVwyeVfCQ550Os3jLrGSNOLgbdAy6s0PBk2TFNjEbsfq31LB0OnX407pJa5v2faRadwSW63mn5KuLyR9j2tgx3zecanl-55R_-jjPs"></script> 
</head>

<body>
  <div id="insegel-container">
    <header>
      <div id="logo-container">
          
          <h1><a href="../../../index.html"> SpaLoR </a> </h1>
          
      </div>
      <div id="project-container">
        
        <h1>Documentation</h1>
        
      </div>
    </header>

    <div id="content-container">

      <div id="main-content-container">
        <div id="main-content" role="main">
          
  <h1>Source code for spalor.algorithms.mc_algorithms</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="o">*</span>

<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">coo_matrix</span>

<span class="kn">from</span> <span class="nn">spalor.regularization.thresholding</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">spalor.matrix_tools.factorization_util</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>

<div class="viewcode-block" id="lmafit"><a class="viewcode-back" href="../../../api_doc/algorithms.mc.html#spalor.algorithms.mc_algorithms.lmafit">[docs]</a><span class="k">def</span> <span class="nf">lmafit</span><span class="p">(</span><span class="n">d1</span><span class="p">,</span> <span class="n">d2</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">known</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    A rank-constrained matrix completion algorithm that uses a successive over-relaxation scheme.  </span>

<span class="sd">    Links for more details:</span>
<span class="sd">    - http://lmafit.blogs.rice.edu/</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    d1 : int</span>
<span class="sd">        number or rows in matrix</span>
<span class="sd">    d2 : int</span>
<span class="sd">        number of columns in matrix</span>
<span class="sd">    r : int </span>
<span class="sd">        target rank of matrix.</span>
<span class="sd">    known : np array</span>
<span class="sd">        array with 2 columns and many rows, indicating indices of the matrix you have a measurement of</span>
<span class="sd">    data : np array</span>
<span class="sd">        vector of measurements, in same order as &#39;known&#39;  </span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Wen, Z., Yin, W. &amp; Zhang, Y. Solving a low-rank factorization model for matrix completion by a nonlinear successive over-relaxation algorithm. Math. Prog. Comp. 4, 333–361 (2012). https://doi.org/10.1007/s12532-012-0044-1</span>


<span class="sd">    &#39;&#39;&#39;</span>   

    <span class="c1"># set parameters</span>
    <span class="c1"># TODO: parameter selection</span>
    <span class="n">tol</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">;</span>
    <span class="n">maxit</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">;</span>
    <span class="n">iprint</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="n">est_rank</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">rank_max</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">floor</span><span class="p">(</span><span class="mf">0.1</span> <span class="o">*</span> <span class="nb">min</span><span class="p">(</span><span class="n">d1</span><span class="p">,</span><span class="n">d2</span><span class="p">)),</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">r</span><span class="p">);</span>
    <span class="n">rank_min</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">rk_jump</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
    <span class="n">init</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="n">save_res</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

    <span class="c1"># Initialize Variables</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">d1</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">d2</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
    <span class="n">Res</span> <span class="o">=</span> <span class="n">data</span> <span class="o">-</span> <span class="n">partXY</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">known</span><span class="p">)</span>
    <span class="n">S</span> <span class="o">=</span> <span class="n">coo_matrix</span><span class="p">((</span><span class="n">Res</span><span class="p">,</span> <span class="n">known</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">d1</span><span class="p">,</span><span class="n">d2</span><span class="p">))</span>
    <span class="n">alf</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">increment</span> <span class="o">=</span> <span class="mf">0.1</span>

    <span class="n">Res</span> <span class="o">=</span> <span class="n">data</span> <span class="o">-</span> <span class="n">partXY</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">known</span><span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Res</span><span class="p">);</span>

    <span class="c1"># main loop</span>

    <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">maxit</span><span class="p">):</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="n">X</span>
        <span class="n">Y0</span> <span class="o">=</span> <span class="n">Y</span>
        <span class="n">Res0</span> <span class="o">=</span> <span class="n">Res</span>
        <span class="n">res0</span> <span class="o">=</span> <span class="n">res</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">+</span> <span class="n">S</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="p">)))</span>
        <span class="n">XXInv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">));</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X0</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">XXInv</span><span class="p">)</span> <span class="o">+</span> <span class="n">S</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">XXInv</span><span class="p">)</span>
        <span class="n">Res</span> <span class="o">=</span> <span class="n">data</span> <span class="o">-</span> <span class="n">partXY</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">known</span><span class="p">)</span>

        <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Res</span><span class="p">);</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="n">res</span> <span class="o">/</span> <span class="n">res0</span><span class="p">;</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        print(&quot;iter: &quot;,iter,&quot; residual: &quot;,res,&quot;alf&quot;, alf)</span>
<span class="sd">        if ratio &gt;= 1:</span>
<span class="sd">            increment = max(0.1 * alf, 0.1 * increment)</span>
<span class="sd">            X = X0</span>
<span class="sd">            Y = Y0</span>
<span class="sd">            Res = Res0</span>
<span class="sd">            res = res0</span>
<span class="sd">            alf = 0</span>
<span class="sd">        elif ratio &gt; 0.7:</span>
<span class="sd">            increment = max(increment, 0.25 * alf)</span>
<span class="sd">            alf = alf + increment</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">S</span> <span class="o">=</span> <span class="n">coo_matrix</span><span class="p">(((</span><span class="n">alf</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">Res</span><span class="p">,</span> <span class="n">known</span><span class="p">))</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span></div>

<div class="viewcode-block" id="alt_proj"><a class="viewcode-back" href="../../../api_doc/algorithms.mc.html#spalor.algorithms.mc_algorithms.alt_proj">[docs]</a><span class="k">def</span> <span class="nf">alt_proj</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">r</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    A very simple matrix completion algorithm comprising of two steps at each iteration:</span>
<span class="sd">        - project L onto set of matrices satisfying the measurements</span>
<span class="sd">        - project L onto the set of rank r matrices</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    m : int</span>
<span class="sd">        number or rows in matrix</span>
<span class="sd">    n : int</span>
<span class="sd">        number of columns in matrix</span>
<span class="sd">    r : int </span>
<span class="sd">        target rank of matrix.</span>
<span class="sd">    X : np array</span>
<span class="sd">        array with 2 columns and many rows, indicating indices of the matrix you have a measurement of</span>
<span class="sd">    y : np array</span>
<span class="sd">        vector of measurements, in same order as &#39;known&#39;  </span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [2] Tanner, J., &amp; Wei, K. (2013). Normalized iterative hard thresholding for matrix completion. SIAM Journal on Scientific Computing, 35(5), S104-S125.</span>
<span class="sd">    &#39;&#39;&#39;</span>   


    <span class="n">L</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">))</span>


    <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2000</span><span class="p">):</span>
        <span class="n">L</span><span class="p">[</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]]</span><span class="o">=</span><span class="n">y</span><span class="p">;</span>
        <span class="n">L</span><span class="o">=</span><span class="n">lowRankProj</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="n">r</span><span class="o">+</span><span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="mi">10</span><span class="o">-</span><span class="nb">iter</span><span class="o">/</span><span class="mi">100</span><span class="p">)));</span>
        <span class="c1"># print(np.linalg.norm(L[X[0,:],X[1,:]]-y))</span>
    <span class="n">u</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">vt</span><span class="o">=</span><span class="n">svds</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="n">r</span><span class="p">)</span>
    <span class="n">U</span><span class="o">=</span><span class="n">u</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s</span><span class="p">));</span>
    <span class="n">V</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vt</span><span class="p">);</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">U</span><span class="p">,</span><span class="n">V</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="svt"><a class="viewcode-back" href="../../../api_doc/algorithms.mc.html#spalor.algorithms.mc_algorithms.svt">[docs]</a><span class="k">def</span> <span class="nf">svt</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">beta_max</span><span class="p">,</span> <span class="n">known</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">r_max</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Singular value thresholding for matrix completion </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    m : int</span>
<span class="sd">        number or rows in matrix</span>
<span class="sd">    n : int</span>
<span class="sd">        number of columns in matrix</span>
<span class="sd">    beta_max : float </span>
<span class="sd">        largest singular value to keep.  Larger values mean less regularization, and less estimtor bias</span>
<span class="sd">    known : np array</span>
<span class="sd">        array with 2 columns and many rows, indicating indices of the matrix you have a measurement of</span>
<span class="sd">    data : np array</span>
<span class="sd">        vector of measurements, in same order as &#39;known&#39;  </span>
<span class="sd">    eps : float</span>
<span class="sd">        stopping criteria.  (default: 1e-5)</span>
<span class="sd">    r_max : int</span>
<span class="sd">        upper bound on the rank of the matrix.  The smaller this is, the faster the algorithm will be</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [3] Cai, J. F., Candès, E. J., &amp; Shen, Z. (2010). A singular value thresholding algorithm for matrix completion. SIAM Journal on optimization, 20(4), 1956-1982.</span>
<span class="sd">    &#39;&#39;&#39;</span>   

    <span class="k">if</span> <span class="n">r_max</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">r_max</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">beta_max</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.2</span> <span class="o">**</span> <span class="mi">30</span><span class="p">)</span>
    <span class="n">maxIter</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>

    <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">maxIter</span><span class="p">):</span>
        <span class="n">X</span><span class="p">[</span><span class="n">known</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">lowRankSoftThresholding</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">beta</span><span class="p">,</span> <span class="n">r_max</span><span class="p">)</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">beta_max</span><span class="p">,</span> <span class="n">beta</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span></div>

<div class="viewcode-block" id="alt_min"><a class="viewcode-back" href="../../../api_doc/algorithms.mc.html#spalor.algorithms.mc_algorithms.alt_min">[docs]</a><span class="k">def</span> <span class="nf">alt_min</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">r</span><span class="p">,</span> <span class="n">Omega</span><span class="p">,</span> <span class="n">known</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    A very simple algorithm for matrix completion via alternating minimization.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    m : int</span>
<span class="sd">        number or rows in matrix</span>
<span class="sd">    n : int</span>
<span class="sd">        number of columns in matrix</span>
<span class="sd">    Omega : np array</span>
<span class="sd">        array with 2 columns and many rows, indicating indices of the matrix you have a measurement of</span>
<span class="sd">    known : np array</span>
<span class="sd">        vector of measurements, in same order as &#39;known&#39;  </span>
<span class="sd">    &#39;&#39;&#39;</span>   

    <span class="n">U</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">r</span><span class="p">)</span>
    <span class="n">V</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">r</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">100</span><span class="p">):</span>   
        
        <span class="n">objU</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">m</span><span class="p">,</span><span class="n">r</span><span class="p">])</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="p">)[</span><span class="n">Omega</span><span class="p">]</span><span class="o">-</span><span class="n">known</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">minimize</span><span class="p">(</span><span class="n">objU</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">m</span><span class="p">,</span><span class="n">r</span><span class="p">])</span>
        
        <span class="n">objV</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">n</span><span class="p">]))[</span><span class="n">Omega</span><span class="p">]</span><span class="o">-</span><span class="n">known</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">minimize</span><span class="p">(</span><span class="n">objV</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">r</span><span class="p">,</span><span class="n">n</span><span class="p">])</span>

        <span class="n">res</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="p">)[</span><span class="n">Omega</span><span class="p">]</span><span class="o">-</span><span class="n">known</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">res</span> <span class="o">&lt;</span> <span class="mf">0.0001</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">U</span><span class="p">,</span><span class="n">V</span><span class="p">)</span></div>
</pre></div>

        </div>
      </div>

      <div id="side-menu-container">

        <div id="search" role="search">
        <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
            <input type="text" name="q" placeholder="Search..." />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
        </form>
</div>

        <div id="side-menu" role="navigation">

          
  
    
  
  
    <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../user_guide/index.html">User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/matrix_completion.html">Matrix Completion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/matrix_completion.html#the-mc-class">The <code class="docutils literal notranslate"><span class="pre">MC</span></code> class</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../user_guide/matrix_completion.html#mathematical-details">Mathematical details</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/robust_PCA.html">Robust Principle Component Analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../user_guide/robust_PCA.html#the-rpca-class">The <code class="docutils literal notranslate"><span class="pre">RPCA</span></code> class</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/Leverage_CX_CUR.html">CUR and CX decomposions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../user_guide/Leverage_CX_CUR.html#the-cx-class">The <code class="docutils literal notranslate"><span class="pre">CX</span></code> class</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../user_guide/Leverage_CX_CUR.html#the-cur-class">The <code class="docutils literal notranslate"><span class="pre">CUR</span></code> class</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../user_guide/Leverage_CX_CUR.html#computing-leverage-sores">Computing leverage sores</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/index.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/PCA_with_missing_data.html">PCA with Missing Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/interpretable_low_rank_models_for_tumour_classification.html">CX Matrix Decompositions for Tumour Classifications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/movie_lens_mc.html">Movie Recomendations with Matrix Completion</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_doc/spalor.html">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_doc/spalor.html#spalor-models">spalor.models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_doc/models.mc.html">MC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_doc/models.robust_pca.html">RPCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_doc/models.cx.html">CX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_doc/models.cur.html">CUR</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_doc/spalor.html#spalor-algorithms">spalor.algorithms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_doc/algorithms.mc.html">mc_algorithms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_doc/algorithms.robust_pca.html">rpca_algorithms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_doc/algorithms.cx.html">cx_algorithms</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_doc/spalor.html#spalor-matrix-tools">spalor.matrix_tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_doc/matrix_tools.factorization_util.html">Factorization tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_doc/matrix_tools.leverage_score.html">leverage_score</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  


        </div>

        

      </div>

    </div>

<footer>
    <div id="footer-info">
        <ul id="build-details">
            

            

            
        </ul>

        
            <div id="copyright">
                &copy; 2022, April Sagan
            </div>
        

        <div id="credit">
            created with <a href="http://sphinx-doc.org/">Sphinx</a> and <a href="https://github.com/Autophagy/insegel">Insegel</a>

        </div>
    </div>

    <a id="menu-toggle" class="fa fa-bars" aria-hidden="true"></a>

    <script type="text/javascript">
      $("#menu-toggle").click(function() {
        $("#menu-toggle").toggleClass("toggled");
        $("#side-menu-container").slideToggle(300);
      });
    </script>

</footer> 

</div>

</body>
</html>